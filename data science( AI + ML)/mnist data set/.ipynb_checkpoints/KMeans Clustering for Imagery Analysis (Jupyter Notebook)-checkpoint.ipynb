{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Clustering for Imagery Analysis\n",
    "### Presented by Eduonix!\n",
    "\n",
    "In this project, we will use a K-means algorithm to perform image classification.  Clustering isn't limited to the consumer information and population sciences, it can be used for imagery analysis as well. Leveraging Scikit-learn and the MNIST dataset, we will investigate the use of K-means clustering for computer vision.\n",
    "\n",
    "In this project, we will learn how to:\n",
    "\n",
    "* Preprocess images for clustering\n",
    "* Deploy K-means clustering algorithms\n",
    "* Use common metrics to evaluate cluster performance\n",
    "* Visualize high-dimensional cluster centroids\n",
    "\n",
    "Let's get started by importing a few of the libraries we will use in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)]\n",
      "Sklearn: 0.23.2\n",
      "Matplotlib: 3.3.0\n",
      "NumPy: 1.18.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Sklearn: {}'.format(sklearn.__version__))\n",
    "print('Matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('NumPy: {}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the MNIST dataset\n",
    "\n",
    "For this project, we will be using the MNIST dataset.  It is available through keras, a deep learning library we have used in previous tutorials. Although we won't be using other features of keras today, it will save us time to import mnist from this library. It is also available through the tensorflow library or for download at http://yann.lecun.com/exdb/mnist/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-be01c8712768>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training Data: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('Training Data: {}'.format(x_train.shape))\n",
    "print('Training Labels: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e581acfe428a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Testing Data: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Testing Labels: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "print('Testing Data: {}'.format(x_test.shape))\n",
    "print('Testing Labels: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# python magic function\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure with 3x3 subplots using matplotlib.pyplot\n",
    "fig, axs = plt.subplots(3, 3, figsize = (12, 12))\n",
    "plt.gray()\n",
    "\n",
    "# loop through subplots and add mnist images\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.matshow(x_train[i])\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Number {}'.format(y_train[i]))\n",
    "    \n",
    "# display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing the MNIST images\n",
    "\n",
    "Images stored as NumPy arrays are 2-dimensional arrays.  However, the K-means clustering algorithm provided by scikit-learn ingests 1-dimensional arrays; as a result, we will need to reshape each image.  \n",
    "\n",
    "Clustering algorithms almost always use 1-dimensional data.  For example, if you were clustering a set of X, Y coordinates, each point would be passed to the clustering algorithm as a 1-dimensional array with a length of two (example: [2,4] or [-1, 4]). If you were using 3-dimensional data, the array would have a length of 3 (example: [2, 4, 1] or [-1, 4, 5]).  \n",
    "\n",
    "MNIST contains images that are 28 by 28 pixels; as a result, they will have a length of 784 once we reshape them into a 1-dimensional array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the images\n",
    "\n",
    "# convert each image to 1 dimensional array\n",
    "X = x_train.reshape(len(x_train),-1)\n",
    "Y = y_train\n",
    "\n",
    "# normalize the data to 0 - 1\n",
    "X = X.astype(float) / 255.\n",
    "\n",
    "print(X.shape)\n",
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. K-Means Clustering\n",
    "\n",
    "Time to start clustering! Due to the size of the MNIST dataset, we will use the mini-batch implementation of k-means clustering provided by scikit-learn.  This will dramatically reduce the amount of time it takes to fit the algorithm to the data. \n",
    "\n",
    "The MNIST dataset contains images of the integers 0 to 9.  Because of this, let's start by setting the number of clusters to 10, one for each digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "n_digits = len(np.unique(y_test))\n",
    "print(n_digits)\n",
    "\n",
    "# Initialize KMeans model\n",
    "kmeans = MiniBatchKMeans(n_clusters = n_digits)\n",
    "\n",
    "# Fit the model to the training data\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Assigning Cluster Labels\n",
    "\n",
    "K-means clustering is an unsupervised machine learning method; consequently, the labels assigned by our KMeans algorithm refer to the cluster each array was assigned to, not the actual target integer.  To fix this, let's define a few functions that will predict which integer corresponds to each cluster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "    \"\"\"\n",
    "    Associates most probable label with each cluster in KMeans model\n",
    "    returns: dictionary of clusters assigned to each label\n",
    "    \"\"\"\n",
    "\n",
    "    inferred_labels = {}\n",
    "\n",
    "    for i in range(kmeans.n_clusters):\n",
    "\n",
    "        # find index of points in cluster\n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "\n",
    "        # append actual labels for each point in cluster\n",
    "        labels.append(actual_labels[index])\n",
    "\n",
    "        # determine most common label\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "\n",
    "        # assign the cluster to a value in the inferred_labels dictionary\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            # append the new number to the existing array at this slot\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            # create a new array in this slot\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "\n",
    "        #print(labels)\n",
    "        #print('Cluster: {}, label: {}'.format(i, np.argmax(counts)))\n",
    "        \n",
    "    return inferred_labels  \n",
    "\n",
    "def infer_data_labels(X_labels, cluster_labels):\n",
    "    \"\"\"\n",
    "    Determines label for each array, depending on the cluster it has been assigned to.\n",
    "    returns: predicted labels for each array\n",
    "    \"\"\"\n",
    "    \n",
    "    # empty array of len(X)\n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)\n",
    "    \n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key\n",
    "                \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the infer_cluster_labels() and infer_data_labels() functions\n",
    "cluster_labels = infer_cluster_labels(kmeans, Y)\n",
    "X_clusters = kmeans.predict(X)\n",
    "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
    "print predicted_labels[:20]\n",
    "print Y[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Optimizing and Evaluating the Clustering Algorithm\n",
    "\n",
    "With the functions defined above, we can now determine the accuracy of our algorithms.  Since we are using this clustering algorithm for classification, accuracy is ultimately the most important metric; however, there are other metrics out there that can be applied directly to the clusters themselves, regardless of the associated labels. Two of these metrics that we will use are inertia and homogeneity. \n",
    "\n",
    "Furthermore, earlier we made the assumption that K = 10 was the appropriate number of clusters; however, this might not be the case.  Let's fit the K-means clustering algorithm with several different values of K, than evaluate the performance using our metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def calculate_metrics(estimator, data, labels):\n",
    "\n",
    "    # Calculate and print metrics\n",
    "    print('Number of Clusters: {}'.format(estimator.n_clusters))\n",
    "    print('Inertia: {}'.format(estimator.inertia_))\n",
    "    print('Homogeneity: {}'.format(metrics.homogeneity_score(labels, estimator.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [10, 16, 36, 64, 144, 256]\n",
    "\n",
    "# test different numbers of clusters\n",
    "for n_clusters in clusters:\n",
    "    estimator = MiniBatchKMeans(n_clusters = n_clusters)\n",
    "    estimator.fit(X)\n",
    "    \n",
    "    # print cluster metrics\n",
    "    calculate_metrics(estimator, X, Y)\n",
    "    \n",
    "    # determine predicted labels\n",
    "    cluster_labels = infer_cluster_labels(estimator, Y)\n",
    "    predicted_Y = infer_data_labels(estimator.labels_, cluster_labels)\n",
    "    \n",
    "    # calculate and print accuracy\n",
    "    print('Accuracy: {}\\n'.format(metrics.accuracy_score(Y, predicted_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test kmeans algorithm on testing dataset\n",
    "# convert each image to 1 dimensional array\n",
    "X_test = x_test.reshape(len(x_test),-1)\n",
    "\n",
    "# normalize the data to 0 - 1\n",
    "X_test = X_test.astype(float) / 255.\n",
    "\n",
    "# initialize and fit KMeans algorithm on training data\n",
    "kmeans = MiniBatchKMeans(n_clusters = 256)\n",
    "kmeans.fit(X)\n",
    "cluster_labels = infer_cluster_labels(kmeans, Y)\n",
    "\n",
    "# predict labels for testing data\n",
    "test_clusters = kmeans.predict(X_test)\n",
    "predicted_labels = infer_data_labels(kmeans.predict(X_test), cluster_labels)\n",
    "    \n",
    "# calculate and print accuracy\n",
    "print('Accuracy: {}\\n'.format(metrics.accuracy_score(y_test, predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualizing Cluster Centroids\n",
    "\n",
    "The most representative point within each cluster is called the centroid. If we were dealing with X,Y points, the centroid would simply be a point on the graph. However, since we are using arrays of length 784, our centroid is also going to be an array of length 784.  We can reshape this array back into a 28 by 28 pixel image and plot it. \n",
    "\n",
    "These graphs will display the most representative image for each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit KMeans algorithm\n",
    "kmeans = MiniBatchKMeans(n_clusters = 36)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# record centroid values\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# reshape centroids into images\n",
    "images = centroids.reshape(36, 28, 28)\n",
    "images *= 255\n",
    "images = images.astype(np.uint8)\n",
    "\n",
    "# determine cluster labels\n",
    "cluster_labels = infer_cluster_labels(kmeans, Y)\n",
    "\n",
    "# create figure with subplots using matplotlib.pyplot\n",
    "fig, axs = plt.subplots(6, 6, figsize = (20, 20))\n",
    "plt.gray()\n",
    "\n",
    "# loop through subplots and add centroid images\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    \n",
    "    # determine inferred label using cluster_labels dictionary\n",
    "    for key, value in cluster_labels.items():\n",
    "        if i in value:\n",
    "            ax.set_title('Inferred Label: {}'.format(key))\n",
    "    \n",
    "    # add image to subplot\n",
    "    ax.matshow(images[i])\n",
    "    ax.axis('off')\n",
    "    \n",
    "# display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
